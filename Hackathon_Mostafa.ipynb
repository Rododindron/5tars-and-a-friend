{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon\n",
    "\n",
    "Some utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.5/dist-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /usr/local/lib/python3.5/dist-packages\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.5/dist-packages (from tables)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from tables)\r\n",
      "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.5/dist-packages (from tables)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "PATH_DATA = '../full.h5'\n",
    "PATH_PREDICT_WITHOUT_GT = '../pred_eighties_from_full_1_without_gt.h5'\n",
    "PATH_SUBMIT = 'pred_from_full_Mostafa_Paul.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "import keras.layers.normalization \n",
    "from keras.callbacks import Callback\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs(h5_path):\n",
    "    f = h5.File(h5_path)\n",
    "    return range(len(f['S2']))\n",
    "\n",
    "def shuffle_idx(sample_idxs):\n",
    "    return list(np.random.permutation(sample_idxs))\n",
    "\n",
    "def split_train_val(sample_idxs, proportion):\n",
    "    n_samples = len(sample_idxs)\n",
    "    return sample_idxs[:int((1.-proportion)*n_samples)], sample_idxs[int((1.-proportion)*n_samples):]\n",
    "\n",
    "def get_batch_count(idxs, batch_size):\n",
    "    batch_count = int(len(idxs)//batch_size)\n",
    "    remained_samples = len(idxs)%batch_size\n",
    "    if remained_samples > 0:\n",
    "        batch_count += 1\n",
    "\n",
    "    return batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    idxs = shuffle_idx(idxs)\n",
    "    while True : \n",
    "        rd = np.random.randint(len(idxs)-10000)\n",
    "        my_idxs = shuffle_idx(idxs[rd:rd+10000])\n",
    "        batch_count = get_batch_count(my_idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = my_idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = f['S2'][batch_idxs, :,:,:]\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = get_idxs(PATH_DATA)\n",
    "shuffled_idxs = shuffle_idx(idxs)\n",
    "train_idxs, val_idxs = split_train_val(shuffled_idxs, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen = generator(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14958592 3739648\n"
     ]
    }
   ],
   "source": [
    "print(train_batch_count*BATCH_SIZE, val_batch_count*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5.File(PATH_DATA, 'r')\n",
    "\n",
    "Y = f['TOP_LANDCOVER']\n",
    "X = f['S2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  9. 10. 11. 12. 13. 14. 15. 17. 18. 19. 20. 21.] [3827110 1250253 2315736  776966 2167443     633    3709 1112499  765705\n",
      " 4054392    1281  634142    3847   86471    3829 1154414  538220    1590]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 18 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19063e8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "print(unique, counts)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.bar(unique, counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 21]\n",
      " [ 1 20]\n",
      " [ 3 12]\n",
      " [ 5 11]\n",
      " [ 2  6]\n",
      " [19  6]\n",
      " [10  5]\n",
      " [ 4  4]\n",
      " [11  4]\n",
      " [14  3]\n",
      " [20  2]\n",
      " [17  0]\n",
      " [15  0]\n",
      " [18  0]\n",
      " [ 9  0]\n",
      " [21  0]\n",
      " [13  0]\n",
      " [ 6  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 18 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18fd6fe128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import operator \n",
    "occu = np.zeros((len(counts), 2))\n",
    "occu[:, 0] = unique\n",
    "occu[: ,1] = counts\n",
    "occu = np.array(sorted(occu, key= operator.itemgetter(1,0), reverse= True))\n",
    "occu = occu.astype(int)\n",
    "occu\n",
    "Total = np.sum(occu[:, 1])\n",
    "\n",
    "occu[: ,1] = occu[: ,1]/Total*100\n",
    "print (occu)\n",
    "plt.bar(range(occu.shape[0]),occu[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[[12 21]\n",
      " [ 1 41]\n",
      " [ 3 53]\n",
      " [ 5 64]\n",
      " [ 2 70]\n",
      " [19 76]\n",
      " [10 81]\n",
      " [ 4 85]\n",
      " [11 89]\n",
      " [14 92]\n",
      " [20 94]\n",
      " [17 94]\n",
      " [15 94]\n",
      " [18 94]\n",
      " [ 9 94]\n",
      " [21 94]\n",
      " [13 94]\n",
      " [ 6 94]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 18 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADlFJREFUeJzt3X+s3fVdx/HnSwrOsQmF3tQOiBcMweAfE9Igk0nIuiCDhaIhhGWZdcM0i0PBaUZ1ybb4F/hjcxoDqYBWQ0aRMSGDuSGDGP+gesvKz7K1YNnalPbOCcwfyYZ7+8f5llwu9/Se3p5z7z0fno/k5nx/fL7nvPO5377u93y+P5qqQpI0/n5sqQuQJA2HgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqxIrF/LBVq1bV5OTkYn6kJI297du3f7eqJuZrt6iBPjk5ydTU1GJ+pCSNvSQvDNLOIRdJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWrEot4pKr0ZTG66f0Hb7bnxMt+jz3ss9H2W63uMikfoktQIA12SGmGgS1IjHEOXZhjWeK+0FDxCl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY3wskU1w0sO9WbnEbokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEd5YpGVhOf8/jdK48AhdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNWKgQE/yO0meTvJUki8keUuS05NsS7I7ydYkx426WElSf/Neh57kFOC3gbOr6n+T3AVcDVwKfK6q7kxyC3ANcPNIq9Wy5DXk0vIw6JDLCuAnkqwA3grsB94D3N2t3wJcMfzyJEmDmjfQq2of8CfAt+kF+cvAduClqnq1a7YXOGVURUqS5jdvoCdZCawHTgfeARwPXDLoByTZmGQqydT09PSCC5UkHd4gQy7vBf69qqar6ofAPcAFwIndEAzAqcC+uTauqs1Vtbaq1k5MTAylaEnSGw0S6N8Gzk/y1iQB1gHPAA8DV3ZtNgD3jqZESdIgBhlD30bv5OdjwJPdNpuBG4CPJ9kNnAzcNsI6JUnzGOjxuVX1aeDTsxY/D5w39IokSQvinaKS1AgDXZIaYaBLUiP8L+je5LxtX2qHR+iS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmN8GmLY2ohT0kEn5QotcwjdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wodzLQEfrCVpFDxCl6RGGOiS1AgDXZIaYaBLUiMGCvQkJya5O8mzSXYmeVeSk5I8mGRX97py1MVKkvob9Aj988A/VtXPAu8EdgKbgIeq6kzgoW5ekrRE5g30JCcAFwK3AVTVD6rqJWA9sKVrtgW4YlRFSpLmN8gR+unANPDXSb6R5NYkxwOrq2p/1+ZFYPWoipQkzW+QQF8BnAvcXFXnAP/NrOGVqiqg5to4ycYkU0mmpqenj7ZeSVIfgwT6XmBvVW3r5u+mF/AHkqwB6F4PzrVxVW2uqrVVtXZiYmIYNUuS5jBvoFfVi8B3kpzVLVoHPAPcB2zolm0A7h1JhZKkgQz6LJffAu5IchzwPPBhen8M7kpyDfACcNVoSpQkDWKgQK+qHcDaOVatG245kqSF8k5RSWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0Y9Fku6kxuun9B2+258bIhVyJJr+cRuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREDB3qSY5J8I8mXu/nTk2xLsjvJ1iTHja5MSdJ8VhxB2+uAncBPdvM3AZ+rqjuT3AJcA9w85PqGanLT/Qvabs+Nlw25EkkavoGO0JOcClwG3NrNB3gPcHfXZAtwxSgKlCQNZtAhlz8DPgH8qJs/GXipql7t5vcCpwy5NknSEZg30JO8HzhYVdsX8gFJNiaZSjI1PT29kLeQJA1gkCP0C4DLk+wB7qQ31PJ54MQkh8bgTwX2zbVxVW2uqrVVtXZiYmIIJUuS5jJvoFfV71fVqVU1CVwNfL2qPgg8DFzZNdsA3DuyKiVJ8zqa69BvAD6eZDe9MfXbhlOSJGkhjuSyRarqEeCRbvp54LzhlyRJWgjvFJWkRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxb6AnOS3Jw0meSfJ0kuu65ScleTDJru515ejLlST1M8gR+qvA71bV2cD5wMeSnA1sAh6qqjOBh7p5SdISWTFfg6raD+zvpr+fZCdwCrAeuKhrtgV4BLhhJFUCk5vuX9B2e268bMiVSNLydERj6EkmgXOAbcDqLuwBXgRWD7UySdIRGTjQk7wN+CJwfVW9MnNdVRVQfbbbmGQqydT09PRRFStJ6m+gQE9yLL0wv6Oq7ukWH0iyplu/Bjg417ZVtbmq1lbV2omJiWHULEmawyBXuQS4DdhZVZ+dseo+YEM3vQG4d/jlSZIGNe9JUeAC4EPAk0l2dMv+ALgRuCvJNcALwFWjKVGSNIhBrnL5FyB9Vq8bbjmSpIXyTlFJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRRxXoSS5J8s0ku5NsGlZRkqQjt+BAT3IM8JfA+4CzgQ8kOXtYhUmSjszRHKGfB+yuquer6gfAncD64ZQlSTpSRxPopwDfmTG/t1smSVoCqaqFbZhcCVxSVb/RzX8I+IWqunZWu43Axm72LOCbCy+3r1XAd0fwvqMwLrWOS51graMyLrWOS52w8Fp/uqom5mu0YgFvfMg+4LQZ86d2y16nqjYDm4/ic+aVZKqq1o7yM4ZlXGodlzrBWkdlXGodlzph9LUezZDLvwFnJjk9yXHA1cB9wylLknSkFnyEXlWvJrkW+CpwDHB7VT09tMokSUfkaIZcqKoHgAeGVMvRGOmQzpCNS63jUidY66iMS63jUieMevh5oSdFJUnLi7f+S1IjxirQ53vUQJIfT7K1W78tyeQS1HhakoeTPJPk6STXzdHmoiQvJ9nR/XxqseucUcueJE92dUzNsT5J/rzr0yeSnLtEdZ41o792JHklyfWz2ixZvya5PcnBJE/NWHZSkgeT7OpeV/bZdkPXZleSDUtU6x8nebb7HX8pyYl9tj3s/rIIdX4myb4Zv+NL+2y7qI8l6VPr1hl17kmyo8+2w+vTqhqLH3onXp8DzgCOAx4Hzp7V5jeBW7rpq4GtS1DnGuDcbvrtwLfmqPMi4MtL3addLXuAVYdZfynwFSDA+cC2ZVDzMcCL9K7NXRb9ClwInAs8NWPZHwGbuulNwE1zbHcS8Hz3urKbXrkEtV4MrOimb5qr1kH2l0Wo8zPA7w2wfxw2Kxaj1lnr/xT41Kj7dJyO0Ad51MB6YEs3fTewLkkWsUaqan9VPdZNfx/YyXjfQbse+NvqeRQ4McmaJa5pHfBcVb2wxHW8pqr+GfjerMUz98ctwBVzbPrLwINV9b2q+k/gQeCSkRXK3LVW1deq6tVu9lF695UsqT59OohFfyzJ4WrtMugq4AujrAHGa8hlkEcNvNam2zlfBk5elOrm0A35nANsm2P1u5I8nuQrSX5uUQt7vQK+lmR7d1fvbMvxEQ9X0/8fx3LpV4DVVbW/m34RWD1Hm+XYvx+h961sLvPtL4vh2m5o6PY+w1jLrU9/CThQVbv6rB9an45ToI+VJG8DvghcX1WvzFr9GL3hgncCfwH8w2LXN8O7q+pcek/N/FiSC5ewlnl1N7FdDvz9HKuXU7++TvW+Wy/7S8qSfBJ4FbijT5Ol3l9uBn4G+HlgP72hjOXuAxz+6HxofTpOgT7IowZea5NkBXAC8B+LUt0MSY6lF+Z3VNU9s9dX1StV9V/d9APAsUlWLXKZh2rZ170eBL5E7+vqTAM94mERvQ94rKoOzF6xnPq1c+DQ8FT3enCONsumf5P8OvB+4IPdH6A3GGB/GamqOlBV/1dVPwL+qs/nL6c+XQH8KrC1X5th9uk4Bfogjxq4Dzh0lcCVwNf77Zij0o2X3QbsrKrP9mnzU4fG9pOcR+/3sBR/eI5P8vZD0/ROjD01q9l9wK91V7ucD7w8YxhhKfQ92lku/TrDzP1xA3DvHG2+ClycZGU3fHBxt2xRJbkE+ARweVX9T582g+wvIzXr/M2v9Pn85fRYkvcCz1bV3rlWDr1PR3nmd9g/9K64+Ba9M9if7Jb9Ib2dEOAt9L6K7wb+FThjCWp8N72v1k8AO7qfS4GPAh/t2lwLPE3v7PujwC8uUX+e0dXweFfPoT6dWWvo/UcmzwFPAmuX8Pd/PL2APmHGsmXRr/T+yOwHfkhvzPYaeudvHgJ2Af8EnNS1XQvcOmPbj3T77G7gw0tU6256486H9tlDV4u9A3jgcPvLItf5d91++AS9kF4zu85u/g1Zsdi1dsv/5tD+OaPtyPrUO0UlqRHjNOQiSToMA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEb8P/SqVzCaBF/lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19063e89e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cum = np.copy(occu)\n",
    "print(occu.shape[0])\n",
    "for i in range(occu.shape[0]):\n",
    "    cum[i, 1] = np.sum(occu[:i+1, 1])\n",
    "    \n",
    "print(cum)\n",
    "plt.bar(range(occu.shape[0]),cum[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  1  3  5  2 19 10  4 11 14 20]\n"
     ]
    }
   ],
   "source": [
    "list_99 = cum[:11, 0]\n",
    "print(list_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmb = len(Y)\n",
    "idxs = range(nmb) \n",
    "#shuffled_idxs = shuffle_idx(idxs)\n",
    "shuffled_idxs =idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " {}\n",
      "100000 \n",
      " {}\n",
      "200000 \n",
      " {}\n",
      "300000 \n",
      " {1.0: 34732, 3.0: 18914, 12.0: 5273, 5.0: 774}\n",
      "400000 \n",
      " {1.0: 54536, 3.0: 45837, 12.0: 20925, 5.0: 1211}\n",
      "500000 \n",
      " {1.0: 64401, 3.0: 72289, 12.0: 53443, 5.0: 1483}\n",
      "600000 \n",
      " {1.0: 68850, 3.0: 100422, 12.0: 106115, 5.0: 1580}\n",
      "700000 \n",
      " {1.0: 69681, 3.0: 106095, 12.0: 119396, 5.0: 34512}\n",
      "800000 \n",
      " {1.0: 69793, 3.0: 107904, 12.0: 126098, 5.0: 100196}\n",
      "900000 \n",
      " {1.0: 69888, 3.0: 109798, 12.0: 135544, 5.0: 169399}\n",
      "1000000 \n",
      " {1.0: 69995, 3.0: 112469, 12.0: 148832, 5.0: 230549}\n",
      "1100000 \n",
      " {1.0: 70072, 3.0: 115107, 12.0: 156009, 5.0: 302799}\n",
      "1200000 \n",
      " {1.0: 70130, 3.0: 117178, 12.0: 158569, 5.0: 387768}\n",
      "1300000 \n",
      " {1.0: 70386, 3.0: 121028, 12.0: 162382, 5.0: 456518}\n",
      "1400000 \n",
      " {1.0: 74180, 3.0: 133516, 12.0: 173395, 5.0: 501052}\n",
      "1500000 \n",
      " {1.0: 79757, 3.0: 156250, 12.0: 189253, 5.0: 537753}\n",
      "1600000 \n",
      " {1.0: 86401, 3.0: 192217, 12.0: 206599, 5.0: 554592}\n",
      "1700000 \n",
      " {1.0: 94522, 3.0: 233113, 12.0: 224921, 5.0: 567632}\n",
      "1800000 \n",
      " {1.0: 98553, 3.0: 265872, 12.0: 254256, 5.0: 583959}\n",
      "1900000 \n",
      " {1.0: 105622, 3.0: 296810, 12.0: 282020, 5.0: 600000}\n",
      "2000000 \n",
      " {1.0: 108620, 3.0: 325285, 12.0: 322043, 5.0: 600000}\n",
      "2100000 \n",
      " {1.0: 109616, 3.0: 360143, 12.0: 361077, 5.0: 600000}\n",
      "2200000 \n",
      " {1.0: 109883, 3.0: 379357, 12.0: 421100, 5.0: 600000}\n",
      "2300000 \n",
      " {1.0: 110051, 3.0: 393745, 12.0: 487344, 5.0: 600000}\n",
      "2400000 \n",
      " {1.0: 110185, 3.0: 404430, 12.0: 554731, 5.0: 600000}\n",
      "2500000 \n",
      " {1.0: 110738, 3.0: 413838, 12.0: 600000, 5.0: 600000}\n",
      "2600000 \n",
      " {1.0: 130706, 3.0: 439791, 12.0: 600000, 5.0: 600000}\n",
      "2700000 \n",
      " {1.0: 149496, 3.0: 473346, 12.0: 600000, 5.0: 600000}\n",
      "2800000 \n",
      " {1.0: 176761, 3.0: 498341, 12.0: 600000, 5.0: 600000}\n",
      "2900000 \n",
      " {1.0: 201049, 3.0: 517709, 12.0: 600000, 5.0: 600000}\n",
      "3000000 \n",
      " {1.0: 215200, 3.0: 529387, 12.0: 600000, 5.0: 600000}\n",
      "3100000 \n",
      " {1.0: 215525, 3.0: 530611, 12.0: 600000, 5.0: 600000}\n",
      "3200000 \n",
      " {1.0: 215738, 3.0: 532046, 12.0: 600000, 5.0: 600000}\n",
      "3300000 \n",
      " {1.0: 215824, 3.0: 532592, 12.0: 600000, 5.0: 600000}\n",
      "3400000 \n",
      " {1.0: 215840, 3.0: 533076, 12.0: 600000, 5.0: 600000}\n",
      "3500000 \n",
      " {1.0: 215963, 3.0: 534156, 12.0: 600000, 5.0: 600000}\n",
      "3600000 \n",
      " {1.0: 216414, 3.0: 536758, 12.0: 600000, 5.0: 600000}\n",
      "3700000 \n",
      " {1.0: 218288, 3.0: 541975, 12.0: 600000, 5.0: 600000}\n",
      "3800000 \n",
      " {1.0: 224589, 3.0: 568541, 12.0: 600000, 5.0: 600000}\n",
      "3900000 \n",
      " {1.0: 225529, 3.0: 590085, 12.0: 600000, 5.0: 600000}\n",
      "4000000 \n",
      " {1.0: 241160, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4100000 \n",
      " {1.0: 253682, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4200000 \n",
      " {1.0: 261890, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4300000 \n",
      " {1.0: 296272, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4400000 \n",
      " {1.0: 349984, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4500000 \n",
      " {1.0: 417955, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4600000 \n",
      " {1.0: 508523, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4700000 \n",
      " {1.0: 564663, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4800000 \n",
      " {1.0: 564800, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "4900000 \n",
      " {1.0: 565000, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "5000000 \n",
      " {1.0: 565030, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "5100000 \n",
      " {1.0: 571432, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "5200000 \n",
      " {1.0: 588162, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "5262863 here\n",
      "2863\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "from collections import Counter\n",
    "import time\n",
    "from sys import stdout\n",
    "#intere = [12,  1,  3,  5,  2, 19, 10,  4, 11, 14, 20]\n",
    "intere = [12,  1,  3,  5]\n",
    "flags = [False]* len(intere)\n",
    "images = []\n",
    "label = []\n",
    "counter ={}\n",
    "seuil = 600000\n",
    "i=0\n",
    "k=0\n",
    "a=0\n",
    "while(True):\n",
    "    lab = Y[shuffled_idxs[a+i],0]\n",
    "    #print(lab)\n",
    "    if lab in intere and counter.get(lab, 0) < seuil:\n",
    "        #print(counter)\n",
    "        images.append(X[shuffled_idxs[a+i]])\n",
    "        label.append(intere.index(lab))\n",
    "        counter[lab] = counter.get(lab, 0)+1\n",
    "        if counter[lab]==seuil:\n",
    "            flags[intere.index(lab)] = True\n",
    "            #print(i)\n",
    "    \n",
    "    i=i+1\n",
    "    \n",
    "    if flags.count(True) == len(intere):\n",
    "        print(k, \"here\")\n",
    "        break\n",
    "    \n",
    "    if (k % 5000==0 and k!=0):\n",
    "        #a = a + 10000 + np.random.randint(100000)\n",
    "        a= a + 5000\n",
    "        i = 0\n",
    "    if (k % 100000==0):\n",
    "        print(a, \"\\n\", counter)\n",
    "        stdout.flush()\n",
    "    if (a == 6000000):\n",
    "        a = 12700000\n",
    "        i = 0\n",
    "    if (a+i> nmb):\n",
    "        break\n",
    "    \n",
    "    k=k+1\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400000, 16, 16, 4)\n",
      "(2400000, 1)\n",
      "{1.0: 600000, 3.0: 600000, 12.0: 600000, 5.0: 600000}\n",
      "5262863\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "label = np.array(label).astype(int).reshape(-1, 1)\n",
    "print(images.shape)\n",
    "print(label.shape)\n",
    "print(counter)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "print (label[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = range(images.shape[0])\n",
    "shuffled_idxs = shuffle_idx(idxs)\n",
    "train_idxs, val_idxs = split_train_val(shuffled_idxs, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(images, label, idxs, batch_size):\n",
    "    \n",
    "    while True : \n",
    "        idxs = shuffle_idx(shuffle_idx(shuffle_idx(idxs)))\n",
    "        rd = np.random.randint(len(idxs)-300*batch_size)\n",
    "        my_idxs = shuffle_idx(idxs[rd:rd+300*batch_size])\n",
    "        batch_count = get_batch_count(my_idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = my_idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = images[batch_idxs, :,:,:]\n",
    "            Y = label[batch_idxs, :]\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), len(intere) )\n",
    "            \n",
    "train_gen = generator(images, label, train_idxs,BATCH_SIZE)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen = generator(images, label, train_idxs, BATCH_SIZE)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33750 3750\n"
     ]
    }
   ],
   "source": [
    "print(train_batch_count, val_batch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (16,16,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, Conv2D, Dropout, MaxPooling2D, Flatten, Activation, AveragePooling2D, concatenate, add\n",
    "\n",
    "\n",
    "inp = Input(shape = input_shape)\n",
    "\n",
    "#x1 = Conv2D(8, (3,3), padding = 'same')(inp)\n",
    "#x1 = BatchNormalization(axis=-1)(x1)\n",
    "#x1 = Activation(\"relu\")(x1)\n",
    "#x2 = Conv2D(8, (3,3), padding = 'same')(x1)\n",
    "#x2 = BatchNormalization(axis=-1)(x2)\n",
    "\n",
    "#conc0 = add([x1, x2])\n",
    "#conc0 = Activation(\"relu\")(conc0)\n",
    "\n",
    "x3 = Conv2D(16, (5,5), padding = 'same')(inp)\n",
    "x3 = BatchNormalization(axis=-1)(x3)\n",
    "x3 = Activation(\"relu\")(x3)\n",
    "x3b = Conv2D(16, (5,5), padding = 'same')(x3)\n",
    "x3b = BatchNormalization(axis=-1)(x3b)\n",
    "\n",
    "conc1 = add([x3b, x3])\n",
    "conc1 = Activation(\"relu\")(conc1)\n",
    "\n",
    "x4 = Conv2D(32, (3,3), padding = 'same')(conc1)\n",
    "x4 = BatchNormalization(axis=-1)(x4)\n",
    "x4 = Activation(\"relu\")(x4)\n",
    "x5 = Conv2D(32, (3,3), padding = 'same')(x4) \n",
    "x5 = BatchNormalization(axis=-1)(x5)\n",
    "\n",
    "conc4 = add([x4, x5])\n",
    "conc4 = Activation(\"relu\")(conc4)\n",
    "\n",
    "x6 = Conv2D(64, (3,3), padding = 'same')(conc4)\n",
    "x6 = BatchNormalization(axis=-1)(x6)\n",
    "x6 = Activation(\"relu\")(x6)\n",
    "x6b = Conv2D(64, (3,3), padding = 'same')(x6) \n",
    "x6b = BatchNormalization(axis=-1)(x6b)\n",
    "\n",
    "conc5 = add([x6, x6b])\n",
    "conc5 = Activation(\"relu\")(conc5)\n",
    "\n",
    "conc5 = MaxPooling2D(pool_size = (2,2))(conc5)\n",
    "\n",
    "# add 256\n",
    "\n",
    "out = Flatten()(conc5)\n",
    "\n",
    "\n",
    "out = Dense(512)(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation(\"relu\")(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Dense(len(intere))(out)\n",
    "out = Activation('softmax')(out)\n",
    "\n",
    "model2 = Model(inp, out)\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=0.0001)\n",
    "#optim = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "model2.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16, 16, 4)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 16)   1616        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 16)   64          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 16)   6416        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 16)   64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 16)   0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 16)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 32)   4640        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 32)   0           activation_39[0][0]              \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 64)   18496       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 64)   36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 64)   0           activation_41[0][0]              \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 64)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 4096)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          2097664     flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 512)          2048        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 512)          0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            2052        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4)            0           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,180,004\n",
      "Trainable params: 2,178,532\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "cback = EarlyStopping(monitor ='loss', patience = 3, mode = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  3/200 [..............................] - ETA: 8s - loss: 0.8684 - acc: 0.6302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=200, validation_steps=150, verbose=1, callbacks=[<keras.ca..., validation_data=<generator..., epochs=150)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 8s 42ms/step - loss: 0.8436 - acc: 0.6431 - val_loss: 0.8256 - val_acc: 0.6494\n",
      "Epoch 2/150\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.8485 - acc: 0.6384 - val_loss: 0.8361 - val_acc: 0.6490\n",
      "Epoch 3/150\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.8506 - acc: 0.6389 - val_loss: 0.8226 - val_acc: 0.6465\n",
      "Epoch 4/150\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.8352 - acc: 0.6455 - val_loss: 0.8338 - val_acc: 0.6438\n",
      "Epoch 5/150\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.8478 - acc: 0.6362 - val_loss: 0.8163 - val_acc: 0.6538\n",
      "Epoch 6/150\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.8472 - acc: 0.6413 - val_loss: 0.8823 - val_acc: 0.6197\n",
      "Epoch 7/150\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.8463 - acc: 0.6423 - val_loss: 0.9496 - val_acc: 0.5778\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit_generator(train_gen, steps_per_epoch=200, epochs=150, verbose=1, validation_data=val_gen,callbacks =[cback], nb_val_samples=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 16, 4)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 16)   592         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 16)   0           batch_normalization_2[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 32)   4640        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 32)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   18496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 64)   0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          1048832     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 23)           5911        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 23)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,128,887\n",
      "Trainable params: 1,127,927\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "cback = EarlyStopping(monitor ='loss', patience = 2, mode = 'min')\n",
    "from keras.models import load_model\n",
    "model = load_model(\"../postultimate_model.dqf\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"../postultimate_model_bfm_7.dqf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction routines\n",
    "\n",
    "In order to submit a result here are some gits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def prediction_generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = f['S2'][batch_idxs, :,:,:]\n",
    "        yield np.array(X)\n",
    "\n",
    "def build_h5_pred_file(pred, h5_output_path):\n",
    "    if os.path.exists(h5_output_path):\n",
    "        os.remove(h5_output_path)\n",
    "    f = h5.File(h5_output_path, 'w')\n",
    "    top_landcover_submit = f.create_dataset(\"TOP_LANDCOVER\", (len(pred), 1), maxshape=(None, 1))\n",
    "    top_landcover_submit[:, 0] = pred\n",
    "    f.close()\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#model = load_model(\"../postultimate_model.dqf\")\n",
    "model = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "1889/1889 [==============================] - 22s 12ms/step\n",
      "241700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction = model.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction))\n",
    "build_h5_pred_file(np.argmax(prediction, axis = 1), PATH_SUBMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 ... 5 5 5]\n",
      "[12  3  1 ... 19 19 19]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_pred = np.argmax(prediction, axis = 1)\n",
    "print(y_pred)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    y_pred[i] = intere[y_pred[i]]\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_SUBMIT1 = \"result_bfm_8.csv\"\n",
    "df2 = pd.DataFrame(y_pred, columns=['TOP_LANDCOVER'])\n",
    "df2.to_csv(PATH_SUBMIT1, index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, Conv2D, Dropout, MaxPooling2D, Flatten, Activation, AveragePooling2D, concatenate, add\n",
    "\n",
    "\n",
    "inp = Input(shape = input_shape)\n",
    "\n",
    "#x1 = Conv2D(16, (3,3), padding = 'same')(inp)\n",
    "#x1 = BatchNormalization(axis=-1)(x1)\n",
    "#x1 = Activation(\"relu\")(x1)\n",
    "#x2 = Conv2D(16, (3,3), padding = 'same')(x1)\n",
    "#x2 = BatchNormalization(axis=-1)(x2)\n",
    "\n",
    "#conc0 = add([x1, x2])\n",
    "#conc0 = Activation(\"relu\")(conc0)\n",
    "\n",
    "x3 = Conv2D(16, (3,3), padding = 'same')(inp)\n",
    "x3 = BatchNormalization(axis=-1)(x3)\n",
    "x3 = Activation(\"relu\")(x3)\n",
    "x3b = Conv2D(16, (3,3), padding = 'same')(x3)\n",
    "x3b = BatchNormalization(axis=-1)(x3b)\n",
    "\n",
    "\n",
    "\n",
    "conc1 = add([x3b, x3])\n",
    "conc1 = Activation(\"relu\")(conc1)\n",
    "\n",
    "x4 = Conv2D(32, (3,3), padding = 'same')(conc1)\n",
    "x4 = BatchNormalization(axis=-1)(x4)\n",
    "x4 = Activation(\"relu\")(x4)\n",
    "x5 = Conv2D(32, (3,3), padding = 'same')(x4) \n",
    "x5 = BatchNormalization(axis=-1)(x5)\n",
    "\n",
    "conc4 = add([x4, x5])\n",
    "conc4 = Activation(\"relu\")(conc4)\n",
    "\n",
    "x6 = Conv2D(64, (3,3), padding = 'same')(conc4)\n",
    "x6 = BatchNormalization(axis=-1)(x6)\n",
    "x6 = Activation(\"relu\")(x6)\n",
    "x6b = Conv2D(64, (3,3), padding = 'same')(x6) \n",
    "x6b = BatchNormalization(axis=-1)(x6b)\n",
    "\n",
    "conc5 = add([x6, x6b])\n",
    "conc5 = Activation(\"relu\")(conc5)\n",
    "\n",
    "conc5 = MaxPooling2D(pool_size = (2,2))(conc5)\n",
    "\n",
    "# add 256\n",
    "\n",
    "out = Flatten()(conc5)\n",
    "\n",
    "\n",
    "out = Dense(256)(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation(\"relu\")(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Dense(23)(out)\n",
    "out = Activation('softmax')(out)\n",
    "\n",
    "model2 = Model(inp, out)\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=0.0001)\n",
    "#optim = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "model2.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
